# -*- coding: utf-8 -*-
"""exam11_classfication_mnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Dh7vDSgEmsKm0vtRiCta0ub5qX-7188l
"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from keras.utils import to_categorical  #onehotencoder해주는 애임.
from tensorflow.keras import datasets

"""이렇게 은닉층을 구성해서 하는게 dnn방식임

DNN (Deep Neural Network)은 딥 러닝에서 가장 기본적인 형태의 신경망입니다. DNN은 여러 개의 은닉층(hidden layer)을 포함한 신경망을 의미하며, 각 은닉층은 여러 개의 뉴런으로 구성됩니다.
"""

(X_train,Y_train), (X_test,Y_test) = datasets.mnist.load_data()
print(X_train.shape, Y_train.shape)
print(X_test.shape, Y_test.shape)

my_sample = np.random.randint(60000)
plt.imshow(X_train[my_sample], cmap='gray')
plt.show()
print(Y_train[my_sample])
print(X_train[my_sample])

y_train = to_categorical(Y_train)
y_test = to_categorical(Y_test)
print(Y_train[5000])
print(y_train[5000])

x_train = X_train.reshape(-1,28*28)
x_test = X_test.reshape(-1,28*28)
x_train = x_train / 255
x_test = x_test / 255
print(x_train.shape)

"""x_train = X_train.reshape(-1, 28*28)와

x_test = X_test.reshape(-1, 28*28)는

주로 이미지 데이터를 평탄화(Flat)하는 작업입니다. 이 작업은 다차원의 이미지를 1차원 벡터로 변환하는 것을 의미합니다.

이 작업을 하는 이유는 주로 다음과 같습니다:

1. 모델 입력 형태에 맞추기:

주로 Fully Connected Layer를 사용하는 신경망(인공신경망) 모델에서는 1차원 벡터 형태의 입력을 기대합니다. 평탄화를 통해 이미지를 1차원으로 만들어 모델에 입력하기 적합한 형태로 조정합니다.
2. 차원 감소:

2D 이미지의 경우, 각 픽셀을 하나의 특성으로 간주하고 이를 1차원으로 나열함으로써 데이터의 차원을 감소시킵니다. 이는 모델의 학습 및 예측 속도를 향상시킬 수 있습니다.
3. 전처리 및 표준화:

1차원으로 평탄화된 형태로 변환하면 각 픽셀은 독립적인 특성으로 간주됩니다. 이를 통해 각 특성을 표준화하거나 전처리하는 등의 작업이 더 쉬워집니다.
4. 일반적인 데이터 포맷:

많은 머신러닝 모델이 이미지 데이터를 1차원으로 받기를 기대하므로, 데이터를 일반적인 형태로 변환하여 사용합니다.


다만, 이러한 평탄화 작업은 이미지의 공간 구조 정보를 완전히 잃어버리게 되므로, Convolutional Neural Network (CNN)과 같이 이미지의 공간 구조를 활용하는 모델에서는 사용하지 않는 것이 일반적입니다. 평탄화를 사용할지 여부는 모델의 종류와 문제의 특성에 따라 결정됩니다.

reshape 함수에서 -1은 해당 차원의 크기를 자동으로 계산하라는 의미를 갖습니다.

여기서는 x_train과 x_test를 2차원 배열로 변환하고 있습니다. 각 이미지는 28x28 크기이므로, reshape(-1, 28*28)은 이미지 데이터를 2차원 배열로 펼치되 각각의 행이 28x28의 이미지를 나타내도록 합니다.

이때 -1을 사용하면, 해당 차원의 크기를 다른 차원들과 호환되도록 자동으로 계산됩니다. 즉, 전체 데이터 크기를 유지하면서 나머지 차원을 맞춰줍니다.

따라서, x_train과 x_test의 shape는 (데이터의 개수, 28*28)로 변환되며, -1을 사용함으로써 데이터의 개수에 따라 자동으로 조절되게 됩니다. 최종적으로 x_train과 x_test는 각각 이미지 데이터를 펼친 2차원 배열이 됩니다.
"""

model = Sequential()
model.add(Dense(128, input_dim=784, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))
model.summary()

"""예를 들어, 3개의 클래스가 있는 다중 클래스 분류 문제에서는 출력층에 3개의 뉴런이 있고, 각 뉴런이 해당 클래스에 대한 확률을 출력하는데 Softmax 함수를 사용합니다. 이렇게 얻은 확률 분포 중에서 가장 높은 확률을 갖는 클래스가 모델의 예측 클래스가 됩니다."""

opt = Adam(learning_rate=0.01)
model.compile(opt, loss='categorical_crossentropy', metrics='accuracy')
fit_hist = model.fit(x_train, y_train, batch_size=256, epochs=15, validation_split=0.2, verbose=1)

score = model.evaluate(x_test, y_test, verbose=0)
print('accuracy',score[1])

plt.plot(fit_hist.history['accuracy'])
plt.show()

my_sample = np.random.randint(10000)
plt.imshow(X_test[my_sample], cmap = 'gray')
print(Y_test[my_sample])
pred = model.predict(x_test[my_sample].reshape(-1,784)) #앞에서 데이터를 데이터프레임 형태로 만들었으니 여기서도 reshape해서 데이터프레임 형태로 만들어함 -1은 자동으로 맞는 형태 찾아주는거임.
print(pred)
print(np.argmax(pred))

