# -*- coding: utf-8 -*-
"""exam01_introduction_to_machine_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qygn2BnBGNWkcdgKQvaPC1VkY2GG5VMY

예제1.

기존의 방식은 공식이 어떻게 되는지 내가 알아야하는데 인공지능을 쓰면 공식이 적용된 데이터만 주면 모델만들어서 학습시키면 됨 그래서 공식몰라도 데이터만 알면 공식 만들어주는거임.

100으로 나누는 스케일링 하는 이유는 값이 크면 에러가 커서 에러가 큰것 때문에 기울기가 커져서 중심점에서 많이 멀어져 값이 발산할 수 있어서 런닝메이트와 마찬가지로 발산할 수 있음 그래서 무한대로 바뀔수 있음 그래서 데이터를 줄이는 거임.
그래서 모델한테 데이터 줄때는 1근처의 값을 주는게 좋고 커도 10안넘게하는게 좋음.
즉 발산을 막기 위해 스케일링하는거임 그리고 나중에 예측값 받아서 업스케일링 즉 100배 다시 곱해주면 됨.

그 이후에 모델한테 1000번 학습시키면 이제 정답에 근접하게 됨.
잡음을 섞어도 값을 찾아냄

이렇게 값을 예측해내는 것을 회귀라고 함. 회귀 즉 되돌아온다. 입력값을 줘서 출력값을 예측하는 것을 회귀라 그러는 이유는 통계에서 회귀라는 의미는

##머신러닝 딥러닝 입문
"""



"""##Linear regression

"""



"""##기존의 프로그램 방식"""

def celsius_to_fahrenheit(x):
  return x * 1.8 + 32

celsius_value = int(input('섭씨온도를 입력하세요.'))
print('화씨온도로', celsius_to_fahrenheit(celsius_value))

"""-shift+enter하면 아래로 내려감
-##이렇게하면 이름 크게 적을 수 있음.
-웨이트, 바이어스, 커널

##머신러닝 방식
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, InputLayer
import numpy as np
import matplotlib.pyplot as plt

"""from tensorflow.keras.models import Sequential: Keras의 Sequential 모델을 불러옵니다. Sequential 모델은 레이어를 순차적으로 쌓아 나가는 간단한 신경망 모델을 나타냅니다.

from tensorflow.keras.layers import Dense, InputLayer: Dense 레이어와 InputLayer를 불러옵니다. Dense 레이어는 fully connected(전결합) 레이어로, 각 노드가 이전 레이어의 모든 노드와 연결되어 있는 레이어입니다. InputLayer는 모델의 입력 레이어를 나타냅니다.

import numpy as np: NumPy 라이브러리를 불러옵니다. NumPy는 배열이나 행렬과 같은 다차원 데이터를 다루기 위한 효과적인 도구를 제공합니다.

import matplotlib.pyplot as plt: Matplotlib 라이브러리를 불러옵니다. Matplotlib은 데이터 시각화를 위한 라이브러리로, 주로 그래프를 그릴 때 사용됩니다.

이 코드는 주로 신경망 모델을 정의할 때 필요한 Keras의 핵심 모듈을 불러오고, 데이터를 다룰 때 사용되는 NumPy와 시각화를 위한 Matplotlib을 임포트하고 있습니다.
"""

data_C = np.array(range(0, 100))
data_F = celsius_to_fahrenheit(data_C)
print(data_C)
print(data_F)

#모델1 만든거 모델2만드려면 model2 이렇게하면됨 model 이거 이름이라 보면됨.
model = Sequential()
model.add(InputLayer(input_shape=(1,)))
model.add(Dense(1))
model.compile(loss='mse', optimizer='rmsprop')  #mse 에러를 제곱해서 평균하는거임 그것을 loss로 하는데 loss가 작아지게끔 학습을 함.
model.summary()

"""Sequential(): Sequential 모델을 생성합니다. Sequential 모델은 각 레이어를 순차적으로 쌓아 나가는 간단한 신경망을 표현합니다.

InputLayer(input_shape=(1,)): 입력 레이어를 추가합니다. 입력 차원은 1이며, 즉, 하나의 특성을 갖는 데이터를 처리하는 모델입니다.

Dense(1): Fully Connected 레이어를 추가합니다. 하나의 뉴런을 가진 출력 레이어로, 선형 회귀 모델의 형태입니다.

model.compile(loss='mse', optimizer='rmsprop'): 모델을 컴파일합니다. 손실 함수는 평균 제곱 오차(Mean Squared Error, 'mse')를 사용하고, 옵티마이저는 'rmsprop'을 사용합니다.

model.summary(): 모델의 구조를 요약하여 표시합니다. 모델의 각 레이어, 출력 모양, 파라미터 개수 등을 확인할 수 있습니다.
"""

scaled_data_C = data_C / 100
scaled_data_F = data_F / 100
print(scaled_data_C)
print(scaled_data_F)

print(model.predict([0.01]))  #아직 학습전이라 제대로 예측 안나옴

#학습시키려는거
model.save('before_learning.h5')    #이렇게하고 저장된거 다운로드

fit_hist = model.fit(scaled_data_C, scaled_data_F, epochs=1000) #1000번 학습시킴,  학습의 결과를 저장함.

"""주어진 코드는 모델을 학습하는 부분입니다. fit_hist 변수에 모델 학습 과정의 히스토리를 저장하는 것으로 보입니다. 코드에서 사용된 model.fit() 함수는 주어진 데이터에 대해 모델을 학습시키고, 학습 과정에서 발생하는 손실 값 등의 정보를 반환합니다.

scaled_data_C: 입력 데이터로서 Celsius 값을 나타내는 배열입니다.
scaled_data_F: 출력 데이터로서 Fahrenheit 값을 나타내는 배열입니다.
epochs=1000: 전체 학습 데이터셋을 1000번 반복해서 학습합니다.
fit() 함수를 호출하면 모델이 주어진 데이터에 대해 학습을 진행하며, 각 에폭(epoch)마다의 손실 값 등의 정보를 fit_hist에 저장합니다. 이후에 이 히스토리를 활용하여 학습 과정을 시각화하거나 분석하는 데 사용할 수 있습니다.

주의: 이 코드가 올바르게 작동하려면 scaled_data_C와 scaled_data_F가 적절한 형태의 NumPy 배열이어야 하며, 데이터의 크기와 모델의 입력 크기가 일치해야 합니다.
"""

print(model.predict([0.01]))  #학습된 후라서 제대로 예측함

model.save('after_learning.h5') #이렇게 치고나서 다운로드하면됨.

plt.plot(fit_hist.history['loss'])
plt.show()      #가로축이 학습된 횟수임.

"""주어진 코드는 학습 과정에서 발생한 손실 값의 변화를 시각화하는 부분입니다. fit_hist.history['loss']에서 손실의 히스토리를 가져와서 Matplotlib을 사용하여 그래프를 그립니다.

각 에폭(epoch)에 따른 손실 값의 변화를 보여주는 그래프가 그려집니다. 그래프를 통해 학습이 진행됨에 따라 손실이 어떻게 감소하는지를 시각적으로 확인할 수 있습니다. 일반적으로 학습이 잘 진행되면 손실이 감소하는 추세를 보입니다.
"""

#데이터에 일부러 잡음 섞으려함
noise = np.array(np.random.normal(0, 0.05, 100))      #np는 넘파이의 노말이라는 함수에 평균이 0 표준편차가 0.05인 정규분포를 랜덤하게 100개 만듬
print(noise)    #현실의 데이터는 정규분포를 따름

#이 온도를 화씨온도에 섞으려함.
noised_scaled_data_F = np.array([])
for data in scaled_data_F:
  noised_scaled_data_F = np.append(
      noised_scaled_data_F , np.random.normal(0, 0.05, 100)+data)   #100개를 100번 반복하니 10000개가 발생함.
print(noised_scaled_data_F)
print(len(noised_scaled_data_F))

"""넘파이는 텍스트및 바이너리 파일로 입력과 출력을 할 수 있다.
넘파이(numpy)의 주요 특징 중의 하나가 n차원 배열(ndarray) 객체이다. 이 객체는 빠르고 유연한 자료형이다. 수학식에서 행렬 연산과 비슷한 연산을 할 수 있다. 즉, 성분별 계산을 할 수 있다.
"""

#여기는 잡음을 섞지않고 입력 데이터를 만듬
noised_scaled_data_C = []   #이름만 그냥 noise라고 한거임 잡음아니고 입력데이터임
for data in range(0,100):
  for i in range(0,100):
    noised_scaled_data_C.append(data)
noised_scaled_data_C = np.array(noised_scaled_data_C)
noised_scaled_data_C = noised_scaled_data_C / 100
print(noised_scaled_data_C)
print(len(noised_scaled_data_C))

plt.scatter(x=noised_scaled_data_C, y=noised_scaled_data_F)     #10000개의 점을 찍은거임.
plt.show()

fig = plt.figure(figsize=(50,50))     #사이즈키우고
ax = fig.add_subplot(111)             #투명도를 줘서 뒤에꺼 겹쳐보이게 함.
ax.scatter(x=noised_scaled_data_C, y=noised_scaled_data_F, alpha=0.2, s=200, marker= '+')
plt.show()

model2 =Sequential()
model2.add(InputLayer(input_shape=(1,)))
model2.add(Dense(1))
model2.compile(loss='mse', optimizer='rmsprop')  #mse 에러를 제곱해서 평균하는거임 그것을 loss로 하는데 loss가 작아지게끔 학습을 함.
model2.summary()

model2.predict([0.01])  #바이어스는 0 커널은 랜덤하게 정해지니 값이 매번 다름

fit_hist = model2.fit(noised_scaled_data_C, noised_scaled_data_F, epochs=20)

model2.save('noised_after_learning.h5')

print(model2.predict([0.01]))

celsius_value = int(input('섭씨 온도를 입력하세요.'))
print('화씨온도로', np.around(model2.predict([celsius_value / 100]) * 100, 1),'입니다.')

plt.plot(fit_hist.history['loss'])
plt.show()

